---
title: "DLA: Dense-Layer-Analysis for Adversarial Example Detection"
collection: publications
permalink: /publication/001-two-stream
excerpt: '
<p align="left">
  <img width="500" height="" src="/images/001-two-stream.png">
</p>'
date: 2019-11-05
paperurl: 'https://arxiv.org/abs/1911.01921'
---
In this paper, we present a novel end-to-end framework to detect such attacks during classification without influencing the target modelâ€™s performance. Inspired by recent research in neuron-coverage guided testing we show that dense layers of DNNs carry security-sensitive information. With a secondary DNN we analyze the activation patterns of the dense layers during classification runtime, which enables effective and real-time detection of adversarial examples.

[Download paper here](https://arxiv.org/abs/1911.01921)
